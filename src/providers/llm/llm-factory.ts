import { ConfigManager } from "@src/utils/config/config-manager";
import { LLMProvider } from "@src/providers/interfaces/llm.interface";
import { OpenAICompatibleLLM } from "./openai-compatible-llm";
import { XunfeiLLM } from "./xunfei-llm";

/**
 * LLM提供者类型枚举
 */
export type LLMProviderType = "OPENAI" | "DEEPSEEK" | "XUNFEI" | "CUSTOM" | "QWEN";

/**
 * 解析LLM提供者配置
 * 支持两种格式:
 * 1. 简单格式: "PROVIDER" - 仅指定提供者类型
 * 2. 扩展格式: "PROVIDER:model" - 指定提供者类型和模型
 */
interface ParsedLLMConfig {
    providerType: LLMProviderType;
    model?: string;
}

/**
 * LLM工厂类，用于创建和管理不同的LLM提供者实例
 */
export class LLMFactory {
    private static instance: LLMFactory;
    private providers: Map<string, LLMProvider> = new Map();
    private configManager: ConfigManager;

    private constructor() {
        this.configManager = ConfigManager.getInstance();
    }

    /**
     * 获取LLM工厂单例
     */
    public static getInstance(): LLMFactory {
        if (!LLMFactory.instance) {
            LLMFactory.instance = new LLMFactory();
        }
        return LLMFactory.instance;
    }

    /**
     * 解析LLM提供者配置字符串
     * @param config 配置字符串，格式为 "PROVIDER" 或 "PROVIDER:model"
     * @returns 解析后的配置对象
     */
    private parseLLMConfig(config: string): ParsedLLMConfig {
        const parts = config.split(':');
        const providerType = parts[0] as LLMProviderType;
        const model = parts.length > 1 ? parts[1] : undefined;

        return { providerType, model };
    }

    /**
     * 获取提供者缓存键
     * 对于指定了模型的提供者，使用 "PROVIDER:model" 作为键
     * @param config 解析后的配置对象
     * @returns 缓存键
     */
    private getProviderCacheKey(config: ParsedLLMConfig): string {
        return config.model ? `${config.providerType}:${config.model}` : config.providerType;
    }

    /**
     * 获取指定类型的LLM提供者
     * @param typeOrConfig LLM提供者类型或配置字符串
     * @param needRefresh 是否需要刷新提供者配置
     * @returns LLM提供者实例
     */
    public async getLLMProvider(typeOrConfig: string | LLMProviderType, needRefresh: boolean = true): Promise<LLMProvider> {
        // 解析配置
        const config = typeof typeOrConfig === 'string'
            ? this.parseLLMConfig(typeOrConfig)
            : { providerType: typeOrConfig };

        // 获取缓存键
        const cacheKey = this.getProviderCacheKey(config);

        // 如果已经创建过该类型的提供者，且不需要刷新，直接返回
        if (this.providers.has(cacheKey) && !needRefresh) {
            return this.providers.get(cacheKey)!;
        }

        // 如果需要刷新且提供者存在，先刷新配置
        if (needRefresh && this.providers.has(cacheKey)) {
            await this.providers.get(cacheKey)!.refresh();
            return this.providers.get(cacheKey)!;
        }

        // 根据类型创建对应的LLM提供者
        let provider: LLMProvider;

        switch (config.providerType) {
            case "OPENAI":
                provider = new OpenAICompatibleLLM("OPENAI_", undefined, config.model);
                break;
            case "DEEPSEEK":
                provider = new OpenAICompatibleLLM("DEEPSEEK_", undefined, config.model);
                break;
            case "XUNFEI":
                // 讯飞不支持指定模型
                if (config.model) {
                    console.warn(`警告: 讯飞API不支持指定模型，将忽略模型设置: ${config.model}`);
                }
                provider = new XunfeiLLM();
                break;
            case "QWEN":
                provider = new OpenAICompatibleLLM("QWEN_", undefined, config.model);
                break;
            case "CUSTOM":
                provider = new OpenAICompatibleLLM("CUSTOM_LLM_", undefined, config.model);
                break;
            default:
                throw new Error(`不支持的LLM提供者类型: ${config.providerType}`);
        }

        // 初始化提供者
        try {
            await provider.initialize();
            this.providers.set(cacheKey, provider);
            return provider;
        } catch (error) {
            console.error(`初始化LLM提供者失败 [${cacheKey}]:`, error);
            throw new Error(`无法初始化LLM提供者 [${cacheKey}]: ${(error as Error).message}`);
        }
    }

    /**
     * 刷新所有已创建的LLM提供者的配置
     */
    public async refreshAllProviders(): Promise<void> {
        const refreshPromises: Promise<void>[] = [];

        for (const [type, provider] of this.providers.entries()) {
            refreshPromises.push(
                provider.refresh().catch(error => {
                    console.error(`刷新LLM提供者配置失败 [${type}]:`, error);
                })
            );
        }

        await Promise.allSettled(refreshPromises);
    }

    /**
     * 获取默认的LLM提供者
     * 从配置中读取DEFAULT_LLM_PROVIDER，如果未配置则默认使用OpenAI
     */
    public async getDefaultProvider(): Promise<LLMProvider> {
        try {
            const defaultProviderConfig = await this.configManager.get("DEFAULT_LLM_PROVIDER") || "OPENAI";
            return this.getLLMProvider(defaultProviderConfig as string);
        } catch (error) {
            console.error("获取默认LLM提供者失败，尝试使用OpenAI作为备选:", error);
            return this.getLLMProvider("OPENAI");
        }
    }
}